{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61599282-3bd8-46fd-a995-d1b172f58433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import CRPS.CRPS as pscore\n",
    "\n",
    "sys.path.append('../../Evaluation/')\n",
    "from conduct_evaluation import ConductEvaluation\n",
    "\n",
    "from normal_evaluation.gamlss_evaluation import SampleOutcomes_GAMLSS_IG\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de1647e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model = SampleOutcomes_GAMLSS_IG\n",
    "trained_model = None\n",
    "sample_model_kwargs = {}\n",
    "N = 10000\n",
    "n_processes = 50\n",
    "\n",
    "get_pscores = lambda likelihoods : [pscore(likelihoods[1][i], likelihoods[2][k][3]).compute()[0] for i, k in enumerate(list(likelihoods[0].keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c715c7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:00<00:00, 3528.23it/s]\n",
      "  0%|          | 0/1202 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "(34, 'Numerical result out of range')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py\", line 108, in sample_case_static\n    return [sample_model.sample_case(case_log) for i in range(n)]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 110, in sample_case\n    duration = self.sample_end_time(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 97, in sample_end_time\n    lam = (pred_mu ** 3) / (pred_sigma ** 2)\n                            ~~~~~~~~~~~^^~~\nOverflowError: (34, 'Numerical result out of range')\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mOverflowError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      8\u001b[39m evaluator_train = ConductEvaluation(\n\u001b[32m      9\u001b[39m     trained_model=trained_model,\n\u001b[32m     10\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     n_processes=n_processes\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m evaluator_test = ConductEvaluation(\n\u001b[32m     18\u001b[39m     trained_model=trained_model,\n\u001b[32m     19\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     n_processes=n_processes\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m likelihoods_test = \u001b[43mevaluator_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m likelihoods_train = evaluator_train.sample_cases(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m results = {\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_train[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_test[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_train)),\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_test))\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py:132\u001b[39m, in \u001b[36mConductEvaluation.sample_cases\u001b[39m\u001b[34m(self, plot_cases, multiprocessing)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Use `imap` to track progress with tqdm\u001b[39;00m\n\u001b[32m    131\u001b[39m     func = partial(ConductEvaluation.sample_case_static, sample_model=\u001b[38;5;28mself\u001b[39m.sample_model, n=\u001b[38;5;28mself\u001b[39m.n)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     sample_results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcase_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m#func = lambda i, c : self.__get_kde_from_samples(sample_results[i], case_data[c][3])\u001b[39;00m\n\u001b[32m    139\u001b[39m     rr = \u001b[38;5;28mlist\u001b[39m(tqdm(\n\u001b[32m    140\u001b[39m         pool.imap(ConductEvaluation._get_kde_from_samples_args, [(sample_results[i], case_data[c][\u001b[32m3\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(case_data)], \u001b[32m500\u001b[39m),\n\u001b[32m    141\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(case_data)\n\u001b[32m    142\u001b[39m     ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/FerdinandFuchs-ZC3r96nX/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:423\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    415\u001b[39m result = IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._taskqueue.put(\n\u001b[32m    417\u001b[39m     (\n\u001b[32m    418\u001b[39m         \u001b[38;5;28mself\u001b[39m._guarded_task_generation(result._job,\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m         result._set_length\n\u001b[32m    422\u001b[39m     ))\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:873\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[31mOverflowError\u001b[39m: (34, 'Numerical result out of range')"
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_IG/train_C.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_IG/test_C.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8d885d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:00<00:00, 5961.08it/s]\n",
      "100%|██████████| 1202/1202 [01:28<00:00, 13.53it/s]\n",
      "100%|██████████| 1202/1202 [00:03<00:00, 347.18it/s]\n",
      "100%|██████████| 4960/4960 [00:01<00:00, 4034.46it/s]\n",
      "100%|██████████| 4960/4960 [01:32<00:00, 53.78it/s] \n",
      "100%|██████████| 4960/4960 [00:03<00:00, 1306.50it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ll_train': Decimal('-1.255840172921644658980983772'),\n",
       " 'll_test': Decimal('-1.109484412597031866482766832'),\n",
       " 'crsp_train': np.float64(24522.667750466095),\n",
       " 'crsp_test': np.float64(24024.938118701277)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/train_D.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/test_D.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d383aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:00<00:00, 3731.66it/s]\n",
      "  0%|          | 0/1202 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Domain error in arguments. The `scale` parameter must be positive for all distributions, and many distributions have restrictions on shape parameters. Please see the `scipy.stats.invgauss` documentation for details.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py\", line 108, in sample_case_static\n    return [sample_model.sample_case(case_log) for i in range(n)]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 110, in sample_case\n    duration = self.sample_end_time(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 100, in sample_end_time\n    sampled_duration = invgauss(mu / lam, scale=lam).rvs()\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/.local/share/virtualenvs/FerdinandFuchs-ZC3r96nX/lib64/python3.12/site-packages/scipy/stats/_distn_infrastructure.py\", line 532, in rvs\n    return self.dist.rvs(*self.args, **kwds)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/.local/share/virtualenvs/FerdinandFuchs-ZC3r96nX/lib64/python3.12/site-packages/scipy/stats/_distn_infrastructure.py\", line 1099, in rvs\n    raise ValueError(message)\nValueError: Domain error in arguments. The `scale` parameter must be positive for all distributions, and many distributions have restrictions on shape parameters. Please see the `scipy.stats.invgauss` documentation for details.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      8\u001b[39m evaluator_train = ConductEvaluation(\n\u001b[32m      9\u001b[39m     trained_model=trained_model,\n\u001b[32m     10\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     n_processes=n_processes\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m evaluator_test = ConductEvaluation(\n\u001b[32m     18\u001b[39m     trained_model=trained_model,\n\u001b[32m     19\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     n_processes=n_processes\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m likelihoods_test = \u001b[43mevaluator_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m likelihoods_train = evaluator_train.sample_cases(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m results = {\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_train[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_test[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_train)),\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_test))\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py:132\u001b[39m, in \u001b[36mConductEvaluation.sample_cases\u001b[39m\u001b[34m(self, plot_cases, multiprocessing)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Use `imap` to track progress with tqdm\u001b[39;00m\n\u001b[32m    131\u001b[39m     func = partial(ConductEvaluation.sample_case_static, sample_model=\u001b[38;5;28mself\u001b[39m.sample_model, n=\u001b[38;5;28mself\u001b[39m.n)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     sample_results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcase_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m#func = lambda i, c : self.__get_kde_from_samples(sample_results[i], case_data[c][3])\u001b[39;00m\n\u001b[32m    139\u001b[39m     rr = \u001b[38;5;28mlist\u001b[39m(tqdm(\n\u001b[32m    140\u001b[39m         pool.imap(ConductEvaluation._get_kde_from_samples_args, [(sample_results[i], case_data[c][\u001b[32m3\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(case_data)], \u001b[32m500\u001b[39m),\n\u001b[32m    141\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(case_data)\n\u001b[32m    142\u001b[39m     ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/FerdinandFuchs-ZC3r96nX/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:423\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    415\u001b[39m result = IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._taskqueue.put(\n\u001b[32m    417\u001b[39m     (\n\u001b[32m    418\u001b[39m         \u001b[38;5;28mself\u001b[39m._guarded_task_generation(result._job,\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m         result._set_length\n\u001b[32m    422\u001b[39m     ))\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:873\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[31mValueError\u001b[39m: Domain error in arguments. The `scale` parameter must be positive for all distributions, and many distributions have restrictions on shape parameters. Please see the `scipy.stats.invgauss` documentation for details."
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/train_CS.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/test_CS.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa22b378",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:00<00:00, 6348.57it/s]\n",
      "100%|██████████| 1202/1202 [01:27<00:00, 13.72it/s]\n",
      "100%|██████████| 1202/1202 [00:03<00:00, 356.02it/s]\n",
      "100%|██████████| 4960/4960 [00:01<00:00, 3901.79it/s]\n",
      "100%|██████████| 4960/4960 [01:37<00:00, 50.85it/s] \n",
      "100%|██████████| 4960/4960 [00:03<00:00, 1325.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ll_train': Decimal('-1.252074099235525439036169859'),\n",
       " 'll_test': Decimal('-1.111481099232885814853584551'),\n",
       " 'crsp_train': np.float64(24536.147667611353),\n",
       " 'crsp_test': np.float64(24064.904989528266)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/train_SD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/test_SD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172c2215",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:01<00:00, 891.48it/s]\n",
      "100%|██████████| 1202/1202 [02:27<00:00,  8.15it/s] \n",
      "100%|██████████| 1202/1202 [00:13<00:00, 91.97it/s]\n",
      "100%|██████████| 4960/4960 [00:03<00:00, 1646.47it/s]\n",
      "100%|██████████| 4960/4960 [03:30<00:00, 23.56it/s]  \n",
      "100%|██████████| 4960/4960 [00:12<00:00, 387.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ll_train': Decimal('-1.905339565782587828865040127'),\n",
       " 'll_test': Decimal('-1.491249398573644645782717523'),\n",
       " 'crsp_train': np.float64(25935.19269140188),\n",
       " 'crsp_test': np.float64(25558.464225517186)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/train_CSD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_SN/test_CSD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FerdinandFuchs-ZC3r96nX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
