{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61599282-3bd8-46fd-a995-d1b172f58433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import CRPS.CRPS as pscore\n",
    "\n",
    "sys.path.append('../../Evaluation/')\n",
    "from conduct_evaluation import ConductEvaluation\n",
    "\n",
    "from normal_evaluation.gamlss_evaluation import SampleOutcomes_GAMLSS_Gamma\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1647e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_model = SampleOutcomes_GAMLSS_Gamma\n",
    "trained_model = None\n",
    "sample_model_kwargs = {}\n",
    "N = 1000\n",
    "n_processes = 50\n",
    "\n",
    "get_pscores = lambda likelihoods : [pscore(likelihoods[1][i], likelihoods[2][k][3]).compute()[0] for i, k in enumerate(list(likelihoods[0].keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c715c7ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:00<00:00, 1294.13it/s]\n",
      "  0%|          | 0/1202 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "scale < 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRemoteTraceback\u001b[39m                           Traceback (most recent call last)",
      "\u001b[31mRemoteTraceback\u001b[39m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 125, in worker\n    result = (True, func(*args, **kwds))\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib64/python3.12/multiprocessing/pool.py\", line 48, in mapstar\n    return list(map(*args))\n           ^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py\", line 108, in sample_case_static\n    return [sample_model.sample_case(case_log) for i in range(n)]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 68, in sample_case\n    duration = self.sample_end_time(\n               ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/FerdinandFuchs/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/normal_evaluation/gamlss_evaluation.py\", line 57, in sample_end_time\n    sampled_duration = np.random.gamma(shape, scale)\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"numpy/random/mtrand.pyx\", line 1743, in numpy.random.mtrand.RandomState.gamma\n  File \"_common.pyx\", line 637, in numpy.random._common.cont\n  File \"_common.pyx\", line 435, in numpy.random._common.check_constraint\nValueError: scale < 0\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m      8\u001b[39m evaluator_train = ConductEvaluation(\n\u001b[32m      9\u001b[39m     trained_model=trained_model,\n\u001b[32m     10\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     14\u001b[39m     n_processes=n_processes\n\u001b[32m     15\u001b[39m )\n\u001b[32m     17\u001b[39m evaluator_test = ConductEvaluation(\n\u001b[32m     18\u001b[39m     trained_model=trained_model,\n\u001b[32m     19\u001b[39m     sample_model_type=sample_model,\n\u001b[32m   (...)\u001b[39m\u001b[32m     23\u001b[39m     n_processes=n_processes\n\u001b[32m     24\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m likelihoods_test = \u001b[43mevaluator_test\u001b[49m\u001b[43m.\u001b[49m\u001b[43msample_cases\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m likelihoods_train = evaluator_train.sample_cases(\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     29\u001b[39m results = {\n\u001b[32m     30\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_train[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     31\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mll_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean([v.ln() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m likelihoods_test[\u001b[32m0\u001b[39m].values()]),\n\u001b[32m     32\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_train\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_train)),\n\u001b[32m     33\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcrsp_test\u001b[39m\u001b[33m\"\u001b[39m: np.mean(get_pscores(likelihoods_test))\n\u001b[32m     34\u001b[39m }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/TaskExecutionTimeMining-gamlss/src/notebooks/PCR/../../Evaluation/conduct_evaluation.py:132\u001b[39m, in \u001b[36mConductEvaluation.sample_cases\u001b[39m\u001b[34m(self, plot_cases, multiprocessing)\u001b[39m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# Use `imap` to track progress with tqdm\u001b[39;00m\n\u001b[32m    131\u001b[39m     func = partial(ConductEvaluation.sample_case_static, sample_model=\u001b[38;5;28mself\u001b[39m.sample_model, n=\u001b[38;5;28mself\u001b[39m.n)\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m     sample_results = \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    133\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcase_data\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcases\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes=\u001b[38;5;28mself\u001b[39m.n_processes) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[32m    138\u001b[39m     \u001b[38;5;66;03m#func = lambda i, c : self.__get_kde_from_samples(sample_results[i], case_data[c][3])\u001b[39;00m\n\u001b[32m    139\u001b[39m     rr = \u001b[38;5;28mlist\u001b[39m(tqdm(\n\u001b[32m    140\u001b[39m         pool.imap(ConductEvaluation._get_kde_from_samples_args, [(sample_results[i], case_data[c][\u001b[32m3\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m i, c \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(case_data)], \u001b[32m500\u001b[39m),\n\u001b[32m    141\u001b[39m         total=\u001b[38;5;28mlen\u001b[39m(case_data)\n\u001b[32m    142\u001b[39m     ))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/FerdinandFuchs-ZC3r96nX/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1178\u001b[39m time = \u001b[38;5;28mself\u001b[39m._time\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1181\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1182\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[32m   1184\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:423\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    415\u001b[39m result = IMapIterator(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m    416\u001b[39m \u001b[38;5;28mself\u001b[39m._taskqueue.put(\n\u001b[32m    417\u001b[39m     (\n\u001b[32m    418\u001b[39m         \u001b[38;5;28mself\u001b[39m._guarded_task_generation(result._job,\n\u001b[32m   (...)\u001b[39m\u001b[32m    421\u001b[39m         result._set_length\n\u001b[32m    422\u001b[39m     ))\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/multiprocessing/pool.py:873\u001b[39m, in \u001b[36mIMapIterator.next\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    871\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m    872\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m value\n",
      "\u001b[31mValueError\u001b[39m: scale < 0"
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/train_C.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/test_C.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f29882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:01<00:00, 1105.58it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 165.83it/s]\n",
      "100%|██████████| 1202/1202 [00:06<00:00, 175.79it/s]\n",
      "100%|██████████| 4960/4960 [00:02<00:00, 2168.78it/s]\n",
      "100%|██████████| 4960/4960 [00:15<00:00, 310.68it/s]\n",
      "100%|██████████| 4960/4960 [00:12<00:00, 408.81it/s]\n"
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/train_CS.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/test_CS.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60f735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:01<00:00, 996.93it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 165.43it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 170.28it/s]\n",
      "100%|██████████| 4960/4960 [00:02<00:00, 2036.60it/s]\n",
      "100%|██████████| 4960/4960 [00:15<00:00, 327.15it/s]\n",
      "100%|██████████| 4960/4960 [00:11<00:00, 420.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/train_CSD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/test_CSD.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d0782",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1202/1202 [00:01<00:00, 1048.55it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 165.52it/s]\n",
      "100%|██████████| 1202/1202 [00:07<00:00, 171.49it/s]\n",
      "100%|██████████| 4960/4960 [00:02<00:00, 1979.01it/s]\n",
      "100%|██████████| 4960/4960 [00:15<00:00, 321.82it/s]\n",
      "100%|██████████| 4960/4960 [00:12<00:00, 384.15it/s]\n"
     ]
    }
   ],
   "source": [
    "train_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/train_CSDCC.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "test_event_log = pd.read_csv(\"../../../data/PCR/predictions_logno/test_CSDCC.csv\", parse_dates=[\"time:timestamp_start\", \"time:timestamp_complete\"])\n",
    "\n",
    "for col in [\"time:timestamp_start\", \"time:timestamp_complete\"]:\n",
    "    train_event_log[col] = pd.to_datetime(train_event_log[col], errors=\"coerce\")\n",
    "    test_event_log[col] = pd.to_datetime(test_event_log[col], errors=\"coerce\")\n",
    "\n",
    "evaluator_train = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=train_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "evaluator_test = ConductEvaluation(\n",
    "    trained_model=trained_model,\n",
    "    sample_model_type=sample_model,\n",
    "    sample_model_kwargs=sample_model_kwargs,\n",
    "    event_log=test_event_log,\n",
    "    n=N,\n",
    "    n_processes=n_processes\n",
    ")\n",
    "\n",
    "likelihoods_test = evaluator_test.sample_cases(False, True)\n",
    "likelihoods_train = evaluator_train.sample_cases(False, True)\n",
    "\n",
    "results = {\n",
    "    \"ll_train\": np.mean([v.ln() for v in likelihoods_train[0].values()]),\n",
    "    \"ll_test\": np.mean([v.ln() for v in likelihoods_test[0].values()]),\n",
    "    \"crsp_train\": np.mean(get_pscores(likelihoods_train)),\n",
    "    \"crsp_test\": np.mean(get_pscores(likelihoods_test))\n",
    "}\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FerdinandFuchs-ZC3r96nX",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
